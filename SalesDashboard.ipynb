{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiros passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packagens\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import date\n",
    "import mysql.connector\n",
    "import pymysql\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#========= Conexões\n",
    "#Para publicar o banco de dados no looker studio, abra o ngrok e digite o comando ngrok tcp 3306\n",
    "\n",
    "token = '?api_token=4ef0bf096ae0fdde361a40a120d18e1db1b973cc'\n",
    "pipedriveURL = 'https://snovio-5a30ce.pipedrive.com/api/v1/'\n",
    "\n",
    "def get_pipedrive(get, params=None):\n",
    "    url = f\"{pipedriveURL}{get}{token}\"             #Building the url\n",
    "    response = requests.get(url, params=params)     #using request\n",
    "    return response.json()\n",
    "\n",
    "connection = pymysql.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"shalazaki\",\n",
    "    database=\"pipedrive\"\n",
    ")\n",
    "\n",
    "# Criar um cursor\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Preparando Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_table(cursor, table_info):\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_info['name']} ({table_info['columns']})\"\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "tables_info = [\n",
    "    {\"name\": \"Deal_Stage\", \"columns\": \"id INT AUTO_INCREMENT, date_update DATETIME, deal_id INT, field_key VARCHAR(255), new_value VARCHAR(255), old_value VARCHAR(255), user_id INT, PRIMARY KEY (id, date_update, deal_id)\"},\n",
    "    {\"name\": \"User\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, name VARCHAR(255), timezone_name VARCHAR(255)\"},\n",
    "    {\"name\": \"Stage\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, order_nr VARCHAR(255), name VARCHAR(255), pipeline_id VARCHAR(255)\"},\n",
    "    {\"name\": \"Pipeline\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, name VARCHAR(255), order_nr VARCHAR(255)\"},\n",
    "    {\"name\": \"Lost_reason\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, label VARCHAR(255)\"},\n",
    "    {\"name\": \"Scheduled\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, label VARCHAR(255)\"},\n",
    "    {\"name\": \"Lead_Score_SDR\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, label VARCHAR(255)\"},\n",
    "    {\"name\": \"Lead_Score_AE\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, label VARCHAR(255)\"},\n",
    "    {\"name\": \"Team\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, label VARCHAR(255)\"},\n",
    "    {\"name\": \"Product\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, label VARCHAR(255)\"},\n",
    "    {\"name\": \"Contact_Made\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, label VARCHAR(255)\"},\n",
    "    {\"name\": \"Origin\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, label VARCHAR(255)\"},\n",
    "    {\"name\": \"Label\", \"columns\": \"id VARCHAR(255) PRIMARY KEY, label VARCHAR(255)\"},\n",
    "    {\"name\": \"max_update_time \", \"columns\": \"max_update_time  DATETIME\"}\n",
    "]\n",
    "\n",
    "with connection.cursor() as cursor:\n",
    "    for table_info in tables_info:\n",
    "        create_table(cursor, table_info)\n",
    "\n",
    "# Certifique-se de fazer commit para salvar as alterações\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Capturando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrutura de Captura de Dados - Construindo tabelas Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### Tabela DEAL ############################################\n",
    "\n",
    "def create_table(cursor, table_name, columns):\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({columns}, page_number TEXT, PRIMARY KEY (id(255)))\"\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "\n",
    "def insert_data(connection, table, data_list, keys):\n",
    "    with connection.cursor() as cursor:\n",
    "        for data in data_list:\n",
    "            # Montar a cláusula ON DUPLICATE KEY UPDATE\n",
    "            update_columns = ', '.join([f\"{key} = %s\" for key in keys])\n",
    "            on_duplicate_key_update = f\" ON DUPLICATE KEY UPDATE {update_columns}\"\n",
    "\n",
    "            # Montar a query SQL completa\n",
    "            sql = f\"INSERT INTO {table} ({', '.join(keys)}) VALUES ({', '.join(['%s'] * len(keys))}) ON DUPLICATE KEY UPDATE {update_columns}\"\n",
    "\n",
    "            # Ajuste aqui: obter valores diretamente do dicionário, com tratamento para 'page_number'\n",
    "            params = [data.get(key, '') if key != 'user_id' else data.get(key, '') for key in keys]  # Corrigido aqui\n",
    "\n",
    "            cursor.execute(sql, params + params)  # Duplicamos os parâmetros para a parte ON DUPLICATE KEY UPDATE\n",
    "\n",
    "    connection.commit()\n",
    "\n",
    "\n",
    "deal_keys = [\n",
    "    \"id\", \"title\", \"owner_name\", \"user_id\", \"value\", \"pipeline_id\", \"stage_id\",\n",
    "    \"add_time\", \"update_time\",\"won_time\",\"lost_time\" ,\"label\", \"status\", \"lost_reason\", \n",
    "    \"4399b1f494a290194a563ff8d051a2931004c32c\",  # Scheduled by\n",
    "    \"856481b27c6718cc6e2872f07d3b7c444114182a\",  # Lead Score SDR\n",
    "    \"8efa88d5da049834ad89cd5158238c463123d91d\",  # Lead Score AE\n",
    "    \"53835fe5eebad73f15ab9552c0cb30d6173565ce\",  # Team\n",
    "    \"58af6c9e65d4df2e0a1273a7bacfe8af10aac1e7\",  # Company Size\n",
    "    \"cd45c2d856d79a012fe5f723a2669058d5d9cb4c\",  # Product\n",
    "    \"021312270ecddc7d5167019c73b28ef262e04861\",  # Linkedin Profile\n",
    "    \"471938728cb3d88d9ccbcf9fe43799730b7bace8\",  # Country\n",
    "    \"39d1d775f22299ba35733d9a2f6ab73a69b7fb87\",  # Job Position\n",
    "    \"a4d67ee86fb981de06b4f0d63be05de236747474\",  # Main Goals\n",
    "    \"060949080c3a6c723d41c3eab8ee6389b9c6b9bf\",  # Contact Made\n",
    "    \"5d40211a6403fecbdc3c861191f66725ac1773b8\"  # Origin\n",
    "]\n",
    "\n",
    "# Criar a tabela\n",
    "deal_columns = [f\"{key} TEXT\" for key in deal_keys]\n",
    "create_table(connection.cursor(), \"Deal\", ', '.join(deal_columns))\n",
    "\n",
    "#Get the last update timestamp\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('SELECT MAX(update_time) FROM deal') #Getting the last time deal updated from SQL\n",
    "timestamp_str = cursor.fetchone()[0] #The value will return a string\n",
    "timestamp_pipedrive = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S') #Converting the string into date\n",
    "timestamp_subtracted = timestamp_pipedrive - timedelta(hours=4) #Subtracting 4 hours to get in Brazil time zone\n",
    "timestamp = timestamp_subtracted.strftime('%Y-%m-%d %H:%M:%S') #Converted to last time deal update in Brazil time zone\n",
    "\n",
    "#timestamp = '2024-04-04 00:00:00' # USAR ESSE SOMENTE QUANDO RESETAR O BANCO DE DADOS\n",
    "\n",
    "# Capturar dados para a tabela Deal\n",
    "page_number = 0\n",
    "more_pages = True\n",
    "\n",
    "while more_pages:\n",
    "    get = 'recents'\n",
    "    params = {\"since_timestamp\":[timestamp],\"limit\":\"500\", \"start\":[page_number], \"items\":\"deal\"}\n",
    "    deal_data = get_pipedrive(get, params)\n",
    "\n",
    "    if deal_data['data'] is not None:\n",
    "        more_pages = deal_data['additional_data']['pagination']['more_items_in_collection']\n",
    "        \n",
    "        with connection.cursor() as cursor:\n",
    "            for deal_dictionary in deal_data['data']:\n",
    "                insert_data(connection, \"Deal\", [deal_dictionary['data']], deal_keys) \n",
    "                cursor.execute(f'UPDATE pipedrive.Deal SET page_number = %s WHERE page_number IS NULL', (page_number,))\n",
    "\n",
    "        \n",
    "        page_number += 500\n",
    "    else:\n",
    "        more_pages = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Deals: 100%|██████████| 3112/3112 [55:40<00:00,  1.07s/it] \n"
     ]
    }
   ],
   "source": [
    "##################################### DEAL_STAGE ############################################\n",
    "\n",
    "#Get the last update timestamp\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('SELECT MAX(date_update) FROM deal_stage') #Getting the last time deal updated from SQL\n",
    "timestamp_subtracted = timestamp_pipedrive - timedelta(hours=4) #Subtracting 4 hours to get in Brazil time zone\n",
    "timestamp = timestamp_subtracted.strftime('%Y-%m-%d %H:%M:%S') #Converted to last time deal update in Brazil time zone\n",
    "\n",
    "# Função para inserir registros na tabela Deal_Stage\n",
    "def insert_deal_stage(params_list):\n",
    "    insert_sql = \"\"\"\n",
    "        INSERT INTO Deal_Stage (date_update, deal_id, field_key, new_value, old_value, user_id)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        ON DUPLICATE KEY UPDATE\n",
    "        new_value = VALUES(new_value),\n",
    "        old_value = VALUES(old_value),\n",
    "        user_id = VALUES(user_id);\n",
    "    \"\"\"\n",
    "    with connection.cursor() as cursor:\n",
    "        for params in params_list:\n",
    "            # Verificar se o registro já existe na tabela\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT COUNT(*)\n",
    "                FROM Deal_Stage\n",
    "                WHERE date_update = %s\n",
    "                AND deal_id = %s\n",
    "                AND field_key = %s;\n",
    "            \"\"\", (params[0], params[1], params[2]))\n",
    "            count = cursor.fetchone()[0]\n",
    "\n",
    "            if count == 0:\n",
    "                cursor.execute(insert_sql, params)\n",
    "                connection.commit()\n",
    "\n",
    "# Capturando IDs de negócios\n",
    "#retomar variavel para update_time >= {timestamp}\n",
    "def get_deal_ids():\n",
    "    select_deal_ids_sql = f\"\"\"\n",
    "        SELECT id FROM deal\n",
    "        WHERE update_time >= \"{timestamp}\";\n",
    "    \"\"\"\n",
    "\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(select_deal_ids_sql)\n",
    "        return [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "# Capturando dados de fluxo de negócios\n",
    "def get_deal_flow(deal_id):\n",
    "    get = f\"deals/{deal_id}/flow\"\n",
    "    params = {\"items\":\"dealChange\",\"limit\":\"500\"}\n",
    "    return get_pipedrive(get,params)\n",
    "\n",
    "\n",
    "def main():\n",
    "    batch_size = 100  # Tamanho do lote para processamento\n",
    "\n",
    "    deal_ids_list = get_deal_ids()\n",
    "    total_deals = len(deal_ids_list)  # Obtenha o número total de deals\n",
    "    batches = [deal_ids_list[i:i+batch_size] for i in range(0, len(deal_ids_list), batch_size)]\n",
    "\n",
    "    processed_deals = 0  # Inicialize o contador de deals processados\n",
    "\n",
    "    with tqdm(total=total_deals, desc=\"Processing Deals\", disable=False) as pbar:\n",
    "        for batch in batches:\n",
    "            params_list = []\n",
    "\n",
    "            for deal_id in batch:\n",
    "                dealflow = get_deal_flow(deal_id)\n",
    "                data_list = dealflow.get('data', [])\n",
    "                \n",
    "                if data_list is not None:\n",
    "                    # Se houver dados disponíveis, prossiga com o processamento\n",
    "                    filtered_results = [\n",
    "                        item for item in data_list \n",
    "                        if item.get('object') == 'dealChange' and \n",
    "                        (item.get('data', {}).get('field_key') == 'stage_id' or \n",
    "                         item.get('data', {}).get('field_key') == 'status' or \n",
    "                         item.get('data', {}).get('field_key') == 'user_id' or\n",
    "                         item.get('data', {}).get('field_key') == 'add_time')\n",
    "                    ]\n",
    "                    for result in filtered_results:\n",
    "                        date_update = result['timestamp']\n",
    "                        field_key = result['data']['field_key']\n",
    "                        new_value = result['data']['new_value']\n",
    "                        old_value = result['data']['old_value']\n",
    "                        user_id = result['data']['user_id']\n",
    "                        params_list.append((date_update, deal_id, field_key, new_value, old_value, user_id))\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            insert_deal_stage(params_list)\n",
    "            processed_deals += len(batch)  # Atualize o contador de deals processados\n",
    "\n",
    "            pbar.update(len(batch))  # Atualize a barra de progresso\n",
    "\n",
    "    return \"All deals processed.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Estrutura de Captura de Dados - Enriquecendo tabelas Dimensão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate Tabelas User e Scheduled para receber novas informações\n",
    "New_Values_UsersAndScheduled = [\n",
    "    \"\"\"\n",
    "    TRUNCATE TABLE user;\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    TRUNCATE TABLE scheduled;\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    TRUNCATE TABLE max_update_time;\n",
    "    \"\"\",\n",
    "\n",
    "]\n",
    "\n",
    "# Executar os comandos SQL\n",
    "for command in New_Values_UsersAndScheduled:\n",
    "    cursor.execute(command)\n",
    "\n",
    "# Commit (confirmar) as alterações\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "#======================================================================\n",
    "#====== 1 - PARAMETROS NATIVOS:\n",
    "#======================================================================  \n",
    "\n",
    "\n",
    "def insert_data(connection, table, data_list, keys):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    for data in data_list:\n",
    "        columns = ', '.join(keys)\n",
    "        values = ', '.join([f\"'{data.get(key, '')}'\" for key in keys])\n",
    "        sql = f\"INSERT INTO {table} ({columns}) VALUES ({values}) ON DUPLICATE KEY UPDATE id=id\"\n",
    "        cursor.execute(sql)\n",
    "\n",
    "    connection.commit()\n",
    "\n",
    "data_mappings = {\n",
    "    \"users\": {\"table\": \"User\", \"keys\": [\"id\", \"name\", \"timezone_name\"]},\n",
    "    \"stages\": {\"table\": \"Stage\", \"keys\": [\"id\", \"order_nr\", \"name\", \"pipeline_id\"]},\n",
    "    \"pipelines\": {\"table\": \"Pipeline\", \"keys\": [\"id\", \"order_nr\", \"name\"]}\n",
    "}\n",
    "\n",
    "# Adicionando o código para outras tabelas no mesmo loop\n",
    "for get, mapping in data_mappings.items():\n",
    "    data_list = get_pipedrive(get)['data']\n",
    "    keys = mapping[\"keys\"]\n",
    "    insert_data(connection, mapping[\"table\"], data_list, keys)\n",
    "\n",
    "\n",
    "\n",
    "#======================================================================\n",
    "#====== 2 - PARAMETROS PERSONALIZADOS:\n",
    "#======================================================================  \n",
    "\n",
    "\n",
    "# Dicionários de parâmetros e tabelas\n",
    "parameter_table_mapping = {\n",
    "    '4399b1f494a290194a563ff8d051a2931004c32c': 'scheduled',\n",
    "    '856481b27c6718cc6e2872f07d3b7c444114182a': 'lead_score_sdr',\n",
    "    \"8efa88d5da049834ad89cd5158238c463123d91d\": 'lead_score_ae',\n",
    "    '53835fe5eebad73f15ab9552c0cb30d6173565ce': 'team',\n",
    "    'cd45c2d856d79a012fe5f723a2669058d5d9cb4c': 'product',\n",
    "    '060949080c3a6c723d41c3eab8ee6389b9c6b9bf': 'contact_made',\n",
    "    '5d40211a6403fecbdc3c861191f66725ac1773b8': 'origin',\n",
    "    'label':'label',\n",
    "    \"lost_reason\":\"lost_reason\"\n",
    "}\n",
    "\n",
    "table_columns_mapping = {\n",
    "    'scheduled': ('id', 'label'),\n",
    "    'lead_score_sdr': ('id', 'label'),\n",
    "    'lead_score_ae': ('id', 'label'),\n",
    "    'team': ('id', 'label'),\n",
    "    'product': ('id', 'label'),\n",
    "    'contact_made': ('id', 'label'),\n",
    "    'origin': ('id', 'label'),\n",
    "    'label': ('id','label'),\n",
    "    'lost_reason': ('id','label')\n",
    "}\n",
    "\n",
    "get = 'dealFields'\n",
    "deal_data = get_pipedrive(get)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "for parameter, table_name in parameter_table_mapping.items():\n",
    "    new_dict = None\n",
    "    for field_dict in deal_data['data']:\n",
    "        if 'key' in field_dict and field_dict['key'] == parameter:\n",
    "            new_dict = field_dict\n",
    "            break\n",
    "    \n",
    "    if new_dict is not None and 'options' in new_dict:\n",
    "        for option in new_dict['options']:\n",
    "            insert_columns = ', '.join(table_columns_mapping[table_name])\n",
    "            insert_values = ', '.join([f\"'{option[column]}'\" for column in table_columns_mapping[table_name]])\n",
    "            insert_query = f\"INSERT INTO {table_name} ({insert_columns}) VALUES ({insert_values}) ON DUPLICATE KEY UPDATE id=id\"\n",
    "            cursor.execute(insert_query)\n",
    "\n",
    "# Certifique-se de fazer commit para salvar as alterações\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizando o banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== 1 - TABELA DEAL_FILTERED ========================================\n",
    "\n",
    "sql_commands = [\n",
    "    \"DROP TABLE IF EXISTS deal_filtered;\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE deal_filtered AS\n",
    "    SELECT * FROM deal;\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    ALTER TABLE deal_filtered\n",
    "    CHANGE COLUMN `4399b1f494a290194a563ff8d051a2931004c32c` scheduled_by TEXT,\n",
    "    CHANGE COLUMN `856481b27c6718cc6e2872f07d3b7c444114182a` lead_score_sdr TEXT,\n",
    "    CHANGE COLUMN `8efa88d5da049834ad89cd5158238c463123d91d` lead_score_ae TEXT,\n",
    "    CHANGE COLUMN `53835fe5eebad73f15ab9552c0cb30d6173565ce` team TEXT,\n",
    "    CHANGE COLUMN `58af6c9e65d4df2e0a1273a7bacfe8af10aac1e7` company_size TEXT,\n",
    "    CHANGE COLUMN `cd45c2d856d79a012fe5f723a2669058d5d9cb4c` product TEXT,\n",
    "    CHANGE COLUMN `021312270ecddc7d5167019c73b28ef262e04861` linkedin_profile TEXT,\n",
    "    CHANGE COLUMN `471938728cb3d88d9ccbcf9fe43799730b7bace8` country TEXT,\n",
    "    CHANGE COLUMN `39d1d775f22299ba35733d9a2f6ab73a69b7fb87` job_position TEXT,\n",
    "    CHANGE COLUMN `a4d67ee86fb981de06b4f0d63be05de236747474` main_goals TEXT,\n",
    "    CHANGE COLUMN `060949080c3a6c723d41c3eab8ee6389b9c6b9bf` contact_made TEXT,\n",
    "    CHANGE COLUMN `5d40211a6403fecbdc3c861191f66725ac1773b8` origin TEXT;\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    UPDATE deal_filtered\n",
    "    SET \n",
    "    add_time = DATE_SUB(add_time, INTERVAL 3 HOUR),\n",
    "    update_time = DATE_SUB(update_time, INTERVAL 3 HOUR),\n",
    "    lost_time = DATE_SUB(lost_time, INTERVAL 3 HOUR);\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    ALTER TABLE deal_filtered\n",
    "    ADD COLUMN Deal_Label VARCHAR(255);\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "# Executar os comandos SQL\n",
    "for command in sql_commands:\n",
    "    cursor.execute(command)\n",
    "\n",
    "# Commit (confirmar) as alterações\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Inserir posteriormente\n",
    "    #\"ALTER TABLE user ADD COLUMN SDR_ID INT;\",\n",
    "    #\"UPDATE user u JOIN scheduled s ON u.name LIKE CONCAT('%', s.label, '%') SET u.SDR_ID = s.id;\",\n",
    "    #\"UPDATE user SET SDR_ID = 275 WHERE name = 'Volodymyr';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== 2 - Tabela New_deal_Stage\n",
    "\n",
    "# Comandos SQL\n",
    "sql_commands = [\n",
    "    \"DROP TABLE IF EXISTS new_deal_stage;\",\n",
    "    \"CREATE TABLE new_deal_stage (date_updated DATETIME, deal_id INT, new_value INT, old_value INT);\",\n",
    "    \"INSERT INTO new_deal_stage SELECT date_update, deal_id, new_value, old_value FROM deal_stage WHERE field_key = 'stage_id';\",\n",
    "    \"INSERT INTO new_deal_stage (date_updated, deal_id, new_value, old_value) SELECT NULL, deal_id, old_value AS new_value, old_value FROM (SELECT deal_id, old_value FROM new_deal_stage WHERE (deal_id, date_updated) IN (SELECT deal_id, MIN(date_updated) FROM new_deal_stage GROUP BY deal_id)) AS latest_deals;\",\n",
    "    \"ALTER TABLE new_deal_stage DROP COLUMN old_value;\",\n",
    "    \"UPDATE new_deal_stage SET date_updated = DATE_SUB(date_updated, INTERVAL 3 HOUR);\",\n",
    "    \"UPDATE new_deal_stage h1 JOIN (SELECT id, add_time FROM deal GROUP BY id) h2 ON h1.deal_id = h2.id SET h1.date_updated = h2.add_time WHERE h1.date_updated IS NULL;\",\n",
    "    \"INSERT INTO new_deal_stage (deal_id, date_updated, new_value) SELECT d.id, d.add_time, d.stage_id FROM deal d LEFT JOIN new_deal_stage nds ON d.id = nds.deal_id WHERE nds.deal_id IS NULL;\",\n",
    "\n",
    "]\n",
    "\n",
    "# Executar os comandos SQL\n",
    "for command in sql_commands:\n",
    "    cursor.execute(command)\n",
    "\n",
    "# Commit (confirmar) as alterações\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== 3 - adaptando user e deal_filtered =============\n",
    "\n",
    "# Comandos SQL\n",
    "sql_commands = [\n",
    "    \"\"\"UPDATE user u\n",
    "    JOIN scheduled s ON u.name LIKE CONCAT('%', s.label, '%')\n",
    "    SET u.SDR_ID = s.id;\"\"\",\n",
    "    \n",
    "    \"\"\"UPDATE user\n",
    "    SET SDR_ID = 275\n",
    "    WHERE name = 'Volodymyr';\"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    update user\n",
    "    set SDR_ID = 329\n",
    "    where name = 'Nathalia Leichsnering Oliveira';\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    update user\n",
    "    set SDR_ID = 294\n",
    "    where name = 'Sofiia';\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"UPDATE user u\n",
    "    SET u.SDR_ID = u.id\n",
    "    WHERE u.SDR_ID IS NULL;\"\"\",\n",
    "    \n",
    "    \"\"\"DELETE FROM user\n",
    "    WHERE id = '15505148';\"\"\",\n",
    "\n",
    "    \"\"\" \n",
    "    INSERT INTO max_update_time (max_update_time)\n",
    "    SELECT MAX(update_time) AS max_update_time\n",
    "    FROM deal_filtered;\n",
    "\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    UPDATE deal_filtered\n",
    "    SET Deal_Label = (\n",
    "        CASE\n",
    "            WHEN label = '65' THEN 'upsell'\n",
    "            WHEN label = '286' THEN 'personal email'\n",
    "            WHEN label = '287' THEN 'outbound'\n",
    "            ELSE 'inbound'\n",
    "        END\n",
    "    );\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Executar os comandos SQL\n",
    "for command in sql_commands:\n",
    "    cursor.execute(command)\n",
    "\n",
    "# Commit (confirmar) as alterações\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
